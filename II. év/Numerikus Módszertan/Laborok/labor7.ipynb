{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Gradient_Method(A, b, x0, max_iter=100, epsilon = 1):\n",
    "    x = x0  # Start with initial guess\n",
    "    for k in range(max_iter):\n",
    "        grad = np.dot(A, x) - b  # Compute gradient\n",
    "        e = -grad  # Descent direction\n",
    "\n",
    "        # Compute step size t\n",
    "        denom = np.dot(e, np.dot(A, e))\n",
    "        if denom == 0:  # Avoid division by zero\n",
    "            break\n",
    "        t = np.dot(e, e) / denom  \n",
    "\n",
    "        # Print descent direction and step size\n",
    "        print(f\"Iteration {k+1}:\")\n",
    "        print(f\"  e = {e}\")\n",
    "        print(f\"  t = {t:.6f}\\n\")\n",
    "\n",
    "        x_new = x + t * e  # Update x\n",
    "\n",
    "        # Stop if change is small\n",
    "        if np.linalg.norm(x_new - x, ord=np.inf) < epsilon:\n",
    "            break\n",
    "        x = x_new\n",
    "\n",
    "    return x\n",
    "\n",
    "def Conjugate_Gradient(A, b, x0, max_iter=100, epsilon=1e-6):\n",
    "    x = x0  # Start with initial guess\n",
    "    r = b - np.dot(A, x)  # Initial residual\n",
    "    e = r  # First direction is just the residual\n",
    "    for k in range(max_iter):\n",
    "        denom = np.dot(e, np.dot(A, e))\n",
    "        if denom == 0:  # Avoid division by zero\n",
    "            break\n",
    "        t = np.dot(r, r) / denom  # Compute step size\n",
    "        \n",
    "        # Print descent direction and step size\n",
    "        print(f\"Iteration {k+1}:\")\n",
    "        print(f\"  e = {e}\")\n",
    "        print(f\"  t = {t:.6f}\\n\")\n",
    "\n",
    "        x_new = x + t * e  # Update x\n",
    "        r_new = r - t * np.dot(A, e)  # Update residual\n",
    "        \n",
    "        # Stop if residual is small\n",
    "        if np.linalg.norm(r_new, ord=np.inf) < epsilon:\n",
    "            break\n",
    "        \n",
    "        beta = np.dot(r_new, r_new) / np.dot(r, r)  # Compute beta\n",
    "        e = r_new + beta * e  # Update search direction\n",
    "        x, r = x_new, r_new  # Update x and residual\n",
    "\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
